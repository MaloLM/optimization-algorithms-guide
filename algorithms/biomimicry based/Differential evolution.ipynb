{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d5ef08",
   "metadata": {},
   "source": [
    "# Differential evolution (DE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfa78c",
   "metadata": {},
   "source": [
    "## Understanding the algorithm\n",
    "\n",
    "Differential Evolution is an evolutionary algorithm primarily used for optimization problems, particularly in continuous domains. Developed by Storn and Price between 1995 and 1997, it is recognized for its simplicity and effective problem-solving capabilities, making it a popular choice among population-based algorithms. DE operates as a stochastic algorithm, meaning it incorporates randomness into its process, and is particularly effective for numerical continuous optimization challenges.\n",
    "\n",
    "The DE algorithm consists of 4 main steps:\n",
    "\n",
    "1. **Initialization**: This involves creating an initial population of candidate solutions, typically represented as vectors of real values. These values correspond to potential solutions in the search space of the optimization problem.\n",
    "\n",
    "2. **Mutation**: In this step, the algorithm modifies the existing population members to explore the solution space. This is done by combining the attributes of different population members in specific ways, leading to new candidate solutions.\n",
    "\n",
    "3. **Crossover**: Also known as recombination, this step involves combining the mutated solutions with existing ones to create a new generation of potential solutions. The crossover mechanism is crucial for maintaining diversity in the population and for allowing the algorithm to explore new areas of the solution space.\n",
    "\n",
    "4. **Selection**: Finally, the selection process determines which candidate solutions are carried over to the next generation. This is usually based on how well they solve the optimization problem, with better-performing solutions being more likely to be selected.\n",
    "\n",
    "A key aspect of DE is its flexibility and adaptability, allowing it to be applied to a wide range of optimization problems. As a metaheuristic algorithm, it makes few assumptions about the problem being optimized and is capable of exploring vast design spaces efficiently. This characteristic makes DE suitable for problems where the solution space is large or poorly understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c7314-7ccd-46de-95a4-0a22010513ae",
   "metadata": {},
   "source": [
    "## Usage examples\n",
    "\n",
    "1. **Parallel Computing**: DE has been utilized effectively in parallel computing environments. It's particularly useful for optimizing problems that are computationally intensive and can benefit from parallel execution.\n",
    "\n",
    "2. **Multiobjective Optimization**: DE is applied in multiobjective optimization scenarios, where it helps in finding solutions that balance trade-offs between two or more conflicting objectives.\n",
    "\n",
    "3. **Constrained Optimization**: In constrained optimization, DE helps in finding the best solution within a given set of constraints, making it suitable for real-world problems where certain limits or requirements must be met.\n",
    "\n",
    "4. **Quantitative Interpretation of Self-Potential Data in Geophysics**: DE has been successfully used for the quantitative interpretation of self-potential data in geophysics. This involves estimating parameters such as electrical dipole moment, depth of the source, and polarization angle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7767bb7",
   "metadata": {},
   "source": [
    "## Strengths\n",
    "\n",
    "1. **Handling Non-Differentiable, Nonlinear, and Multimodal Functions**: DE excels in managing non-differentiable, nonlinear, and multimodal cost functions. This capability is crucial when dealing with real-world optimization problems that are complex and don't conform to simpler, linear models.\n",
    "\n",
    "2. **Parallelizability**: The algorithm is well-suited for parallel computation, making it effective for computationally intensive tasks. This aspect allows for efficient processing of large-scale problems by distributing the workload across multiple processors or machines.\n",
    "\n",
    "3. **Ease of Use with Few Control Variables**: DE is user-friendly, requiring only a few control variables to guide the optimization process. These variables are robust and straightforward to select, reducing the complexity often associated with tuning optimization algorithms.\n",
    "\n",
    "4. **Good Convergence Properties**: It consistently converges to the global minimum in independent trials, indicating its reliability in finding optimal solutions across different problem instances.\n",
    "\n",
    "5. **Capability with Multidimensional Real-Valued Functions**: DE can optimize multidimensional real-valued functions without the need for gradient information. This means it can address optimization problems that are non-continuous, noisy, or subject to change over time, broadening its applicability.\n",
    "\n",
    "6. **Incorporates Directional Information**: Unlike conventional genetic algorithms, DE employs a target and unit vector, which allows for quicker convergence on solutions. However, this may come at the expense of exploration.\n",
    "\n",
    "7. **Simplicity and Speed**: DE is valued for its straightforwardness and rapid execution. It employs real coding, which is easy to understand and implement, and also features a local search mechanism for enhanced efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb1301",
   "metadata": {},
   "source": [
    "## Weaknesses\n",
    "\n",
    "1. **Parameter Sensitivity and Selection**: The performance of DE is highly dependent on the trial vector generation scheme and the adjustment of its control parameters. Finding the optimal values for these parameters can be time-consuming and challenging, especially for complex problems. This sensitivity necessitates a problem-specific approach to parameter selection, which can be a significant drawback in applications where quick and easy configuration is needed.\n",
    "\n",
    "2. **Effort in Fine-Tuning Parameters**: The mutation factor (F) and crossover probability (CR) are critical to DE's performance. The trial-and-error method used to fine-tune these parameters can be successful, but it demands considerable time and effort. Moreover, the optimal settings for these parameters tend to be problem-specific, adding to the complexity of using DE in diverse scenarios.\n",
    "\n",
    "3. **Selection of Penalty Coefficient**: In DE, the selection of the penalty coefficient is a significant challenge. If the penalty coefficient is set too low, it may not effectively enforce constraints. Conversely, if it's set too high, it can greatly slow down or even halt the convergence process. This aspect is crucial because it impacts the effectiveness of the algorithm in constrained optimization problems.\n",
    "\n",
    "4. **Premature Convergence and Evolutionary Stagnation**: As the DE algorithm evolves, with an increase in generations, the population diversity can worsen. This leads to premature convergence or evolutionary stagnation, which is detrimental for an algorithm that relies on population differences. This weakness is particularly problematic as it impacts the algorithm's ability to find optimal solutions in diverse scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede478d",
   "metadata": {},
   "source": [
    "## Python demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19580a",
   "metadata": {},
   "source": [
    "\n",
    "### DE on multiple complex functions\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Bellow process is intense. <br> It creates the GIF animations displayed bellow. <br> Refresh the current page to update displayed animations after a new generation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6142a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Random generator\n",
    "rng_engine = np.random.default_rng(seed=None)\n",
    "\n",
    "class DifferentialEvolution:\n",
    "    def __init__(self, objective_function, bounds, population_size=100, crossover_probability=0.7, differential_weight=0.8, max_generations=100):\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds\n",
    "        self.population_size = population_size\n",
    "        self.crossover_probability = crossover_probability\n",
    "        self.differential_weight = differential_weight\n",
    "        self.max_generations = max_generations\n",
    "        self.dimensions = len(bounds)\n",
    "        self.population = np.random.rand(population_size, self.dimensions) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        self.best_solution = None\n",
    "        self.population_history = []\n",
    "        self.fitness_history = []\n",
    "\n",
    "    def optimize(self):\n",
    "        self.fitness_history = []\n",
    "        best_fitness = float('inf')\n",
    "\n",
    "        for _ in range(self.max_generations):\n",
    "            for i in range(self.population_size):\n",
    "                # Mutation\n",
    "                idxs = [idx for idx in range(self.population_size) if idx != i]\n",
    "                a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n",
    "                mutant_vector = np.clip(a + self.differential_weight * (b - c), self.bounds[0], self.bounds[1])\n",
    "\n",
    "                # Crossover\n",
    "                trial_vector = np.where(np.random.rand(self.dimensions) < self.crossover_probability, mutant_vector, self.population[i])\n",
    "\n",
    "                # Selection\n",
    "                if self.objective_function(*trial_vector) < self.objective_function(*self.population[i]):\n",
    "                    self.population[i] = trial_vector\n",
    "\n",
    "            # Find the best individual\n",
    "            fitness = np.array([self.objective_function(*ind) for ind in self.population])\n",
    "            min_fitness_idx = np.argmin(fitness)\n",
    "            min_fitness = fitness[min_fitness_idx]\n",
    "\n",
    "            if min_fitness < best_fitness:\n",
    "                best_fitness = min_fitness\n",
    "                self.best_solution = self.population[min_fitness_idx]\n",
    "            \n",
    "            self.fitness_history.append(best_fitness)\n",
    "\n",
    "            self.population_history.append(self.population.copy())\n",
    "\n",
    "        return self.best_solution\n",
    "    \n",
    "    def plot_fitness(self):\n",
    "        # Plotting the results\n",
    "        plt.plot(self.fitness_history)\n",
    "        plt.title(\"Differential Evolution Optimization of Rastrigin Function\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Best Fitness (Min Rastrigin Value)\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Define the four functions to optimize\n",
    "def rastrigin_function(x, y):\n",
    "    A = 10\n",
    "    n = 2\n",
    "    return A * n + (x**2 - A * np.cos(2 * np.pi * x)) + (y**2 - A * np.cos(2 * np.pi * y))\n",
    "\n",
    "def ackley_function(x, y):\n",
    "    a = 20\n",
    "    b = 0.2\n",
    "    c = 2 * np.pi\n",
    "    sum_sq_term = -0.5 * (x**2 + y**2)\n",
    "    cos_term = np.cos(c * x) + np.cos(c * y)\n",
    "    return -a * np.exp(b * sum_sq_term) - np.exp(0.5 * cos_term) + a + np.exp(1)\n",
    "\n",
    "def rosenbrock_function(x, y, a=1, b=100):\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "def goldstein_price_function(x, y):\n",
    "    part1 = (1 + (x + y + 1)**2 * (19 - 14*x + 3*x**2 - 14*y + 6*x*y + 3*y**2))\n",
    "    part2 = (30 + (2*x - 3*y)**2 * (18 - 32*x + 12*x**2 + 48*y - 36*x*y + 27*y**2))\n",
    "    return part1 * part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea1f580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution for Rosenbrock_DE (x, y) = (2.750277944940649e-06, 5.553291515525416e-07) with value z = [2.75027794e-06 5.55329152e-07] \n",
      " Saved at ./assets/images/Rosenbrock_DE/Rosenbrock_DE.gif \n",
      "\n",
      "Best solution for Goldstein_Price_DE (x, y) = (1.7248131856106852e-06, -2.356046175933102e-07) with value z = [ 1.72481319e-06 -2.35604618e-07] \n",
      " Saved at ./assets/images/Goldstein_Price_DE/Goldstein_Price_DE.gif \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Function to generate and save plots for each frame\n",
    "def plot_frame(frame, trails, fitness_history, function, function_name, X, Y, Z, known_optima, save_path):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Set the title for the entire figure\n",
    "    fig.suptitle(f\"{function_name} function - Iteration {frame}\", fontsize=16)\n",
    "\n",
    "    # 2D plot\n",
    "    ax1 = fig.add_subplot(221)  # Changed to 221 for a 2x2 grid (top left)\n",
    "    ax1.contourf(X, Y, Z, levels=200, cmap='viridis')\n",
    "    \n",
    "    for trail in trails:\n",
    "        if len(trail) > frame:\n",
    "            ax1.plot(*trail[frame], 'ro')\n",
    "    ax1.set_title(\"2D View\")\n",
    "\n",
    "    # 3D plot\n",
    "    ax2 = fig.add_subplot(222, projection='3d')  # Changed to 222 for a 2x2 grid (top right)\n",
    "    ax2.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.7)\n",
    "    for trail in trails:\n",
    "        if len(trail) > frame:\n",
    "            ax2.scatter(*trail[frame], function(*trail[frame]), color='r', s=50)\n",
    "\n",
    "    # Plotting known optima\n",
    "    for opt in known_optima:\n",
    "        ax1.scatter(opt[0], opt[1], color='green', s=300, marker='x', label='Known Optima')\n",
    "        ax2.scatter(opt[0], opt[1], opt[2], color='green', s=500, marker='x', label='Known Optima')\n",
    "\n",
    "    ax2.set_title(\"3D View\")\n",
    "    ax2.set_xlabel('X axis')\n",
    "    ax2.set_ylabel('Y axis')\n",
    "    ax2.set_zlabel('Z axis')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Fitness History Plot\n",
    "    ax3 = fig.add_subplot(212)  # New subplot for fitness history (bottom row)\n",
    "    ax3.plot(fitness_history[:frame+1])\n",
    "    ax3.set_title(\"Fitness History\")\n",
    "    ax3.set_xlabel(\"Generation\")\n",
    "    ax3.set_ylabel(\"Best Fitness (Min Rastrigin Value)\")\n",
    "\n",
    "    plt.close(fig)\n",
    "    fig.savefig(save_path)\n",
    "\n",
    "def create_gif(function, function_name, num_iterations, bounds, population_size, crossover_probability, differential_weight, known_optima):\n",
    "    \n",
    "    # Initialize DE\n",
    "    de = DifferentialEvolution(rastrigin_function, bounds, population_size, crossover_probability, differential_weight, max_generations)\n",
    "    de.optimize()\n",
    "\n",
    "    # Prepare for visualization\n",
    "    x = np.linspace(bounds[0], bounds[1], 200)\n",
    "    y = np.linspace(bounds[0], bounds[1], 200)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = function(X, Y)\n",
    "\n",
    "    # Generate and save each frame as an image\n",
    "    gif_dir = f\"./assets/images/{function_name}\"\n",
    "    os.makedirs(gif_dir, exist_ok=True)\n",
    "    filenames = []\n",
    "    for frame in range(num_iterations):\n",
    "        frame_path = f\"{gif_dir}/frame_{frame:04d}.png\"\n",
    "        plot_frame(frame, de.population_history, de.fitness_history, function, function_name, X, Y, Z, known_optima, frame_path)\n",
    "        filenames.append(frame_path)\n",
    "    \n",
    "    # Create the GIF using imageio\n",
    "    gif_path = f\"{gif_dir}/{function_name}.gif\"\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=0.2, loop=0) as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # Clean up the individual frames\n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n",
    "\n",
    "    # Print the best solution\n",
    "    best_position = de.best_solution\n",
    "    best_value = de.best_solution\n",
    "    print(f\"Best solution for {function_name} (x, y) = ({best_position[0]}, {best_position[1]}) with value z = {best_value} \\n Saved at {gif_path} \\n\")\n",
    "\n",
    "known_optima_rastrigin = [(0, 0, 0)] # x, y, z\n",
    "known_optima_ackley = [(0, 0, 0)] # x, y, z\n",
    "known_optima_rosenbrock = [(1, 1, 0)] # x, y, z\n",
    "known_optima_goldstein_price = [(0, -1, 3)] # x, y, z\n",
    "\n",
    "bounds = [-6, 6]\n",
    "# bounds:\n",
    "# Defines the range of the search space for each dimension of the problem. In this case, the bounds are set to [-10, 10],\n",
    "# meaning that the algorithm will search for solutions within this interval for each variable. Appropriate bounds are\n",
    "# crucial as they can affect the efficiency of the search process and the quality of the final solution.\n",
    "\n",
    "population_size = 100\n",
    "# population_size:\n",
    "# Specifies the number of candidate solutions (individuals) in the population. A larger population size allows for a\n",
    "# wider exploration of the search space, potentially leading to better solutions but at the cost of increased computational\n",
    "# effort. Conversely, a smaller population size might reduce the computational load but can risk missing out on\n",
    "# potentially better solutions.\n",
    "\n",
    "max_generations = 100\n",
    "# max_generations:\n",
    "# Determines the number of iterations (generations) the algorithm will run. This is a stopping criterion for the algorithm.\n",
    "# A larger number of generations allows for more thorough exploration of the search space, increasing the chances of\n",
    "# finding an optimal or near-optimal solution. However, it also means more computational time.\n",
    "\n",
    "crossover_probability = 0.5\n",
    "# crossover_probability:\n",
    "# Indicates the probability of crossover (genetic recombination) occurring during the generation of trial vectors. A value\n",
    "# of 0.5 means there is a 50% chance that each component of the trial vector is taken from the mutant vector. This\n",
    "# parameter balances between exploration (high values) and exploitation (low values) of the search space.\n",
    "\n",
    "differential_weight = 1\n",
    "# differential_weight:\n",
    "# This parameter, often denoted as F, controls the amplification of the differential variation between two population\n",
    "# members. It influences the step sizes in the mutation process. A value of 0.6 suggests moderate perturbations in the\n",
    "# generation of mutant vectors. Higher values can lead to more aggressive exploration but may also increase the risk of\n",
    "# overshooting optimal solutions, while lower values tend to encourage more localized search.\n",
    "\n",
    "\n",
    "# create_gif(rastrigin_function, 'Rastrigin_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_rastrigin)\n",
    "# create_gif(ackley_function, 'Ackley_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_ackley)\n",
    "create_gif(rosenbrock_function, 'Rosenbrock_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_rosenbrock)\n",
    "create_gif(goldstein_price_function, 'Goldstein_Price_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_goldstein_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ba8ce",
   "metadata": {},
   "source": [
    "![](../../assets/images/Ackley_DE/Ackley_DE.gif)\n",
    "<br>\n",
    "\n",
    "![](../../assets/images/Goldstein_Price_DE/Goldstein_Price_DE.gif)\n",
    "<br>\n",
    "\n",
    "![](../../assets/images/Rastrigin_DE/rastrigin_DE.gif)\n",
    "<br>\n",
    "\n",
    "![](../../assets/images/Rosenbrock_DE/rosenbrock_DE.gif)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of demonstration\n",
    "\n",
    "---\n",
    "\n",
    "## Practical optimization tools\n",
    "\n",
    "2. [**DEAP (Python):**](https://github.com/DEAP/deap) DEAP (Distributed Evolutionary Algorithms in Python) is an open-source framework for evolutionary computation. It provides a versatile collection of evolutionary algorithms, including differential evolution. DEAP stands out for its ease of use and flexibility, allowing users to easily customize genetic algorithms and other evolutionary strategies for their specific problems.\n",
    "\n",
    "3. [**Julia (Julia Language):**](https://julialang.org/) Julia, a high-performance programming language for technical computing, includes various packages for optimization and evolutionary algorithms. One such package is `BlackBoxOptim`, which supports differential evolution. Julia is renowned for its speed and efficiency, particularly in mathematical computing, making it a popular choice for implementing complex algorithms like differential evolution.\n",
    "\n",
    "4. [**Nevergrad (Python):**](https://github.com/facebookresearch/nevergrad) Nevergrad is an open-source Python library designed for derivative-free and blackbox optimization. It includes a wide range of optimization algorithms, including differential evolution. Known for its ability to handle noisy, real-world problems, Nevergrad is widely used in both academia and industry for optimization tasks that are difficult to model explicitly.\n",
    "\n",
    "5. [**Jenetics (Java):**](https://jenetics.io/) Jenetics is an advanced Genetic Algorithm, respectively an Evolutionary Algorithm, library written in modern-day Java. It includes support for differential evolution as part of its suite of evolutionary algorithms. Jenetics is appreciated for its robustness and performance, making it a strong choice for Java developers needing evolutionary computation capabilities.\n",
    "\n",
    "5. [**Pagmo/Pygmo (C++/Python):**](https://www.esa.int/gsp/ACT/open_source/pagmo/) Pagmo is a C++ library for scientific computing and optimization, particularly focused on global and multi-objective optimization problems. It includes the differential evolution algorithm among many other optimization algorithms. Pygmo is the Python version of this library. Pagmo is distinguished by its architecture that facilitates solving complex optimization problems and its integration with other scientific tools in C++ and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "| Sources |\n",
    "|---------|\n",
    "| [Differential evolution - Wikipedia](https://en.wikipedia.org/wiki/Differential_evolution) |\n",
    "| [Differential Evolution from Scratch in Python - Machinelearningmastery](https://machinelearningmastery.com/differential-evolution-from-scratch-in-python/) |\n",
    "| [Exploring differential evolution in AI - indiaai](https://indiaai.gov.in/article/exploring-differential-evolution-in-ai) |\n",
    "| [A Comparative Study of Differential Evolution Variants in Constrained Structural Optimization - Frontiers](https://www.frontiersin.org/articles/10.3389/fbuil.2020.00102/full) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
