{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d5ef08",
   "metadata": {},
   "source": [
    "# Differential Evolution (DE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfa78c",
   "metadata": {},
   "source": [
    "## Understanding The Algorithm\n",
    "\n",
    "Differential Evolution is an evolutionary algorithm primarily used for optimization problems, particularly in continuous domains. Developed by Storn and Price between 1995 and 1997, it is recognized for its simplicity and effective problem-solving capabilities, making it a popular choice among population-based algorithms. DE operates as a stochastic algorithm, meaning it incorporates randomness into its process, and is particularly effective for numerical continuous optimization challenges.\n",
    "\n",
    "The DE algorithm consists of 4 main steps:\n",
    "\n",
    "1. **Initialization**: This involves creating an initial population of candidate solutions, typically represented as vectors of real values. These values correspond to potential solutions in the search space of the optimization problem.\n",
    "\n",
    "2. **Mutation**: In this step, the algorithm modifies the existing population members to explore the solution space. This is done by combining the attributes of different population members in specific ways, leading to new candidate solutions.\n",
    "\n",
    "3. **Crossover**: Also known as recombination, this step involves combining the mutated solutions with existing ones to create a new generation of potential solutions. The crossover mechanism is crucial for maintaining diversity in the population and for allowing the algorithm to explore new areas of the solution space.\n",
    "\n",
    "4. **Selection**: Finally, the selection process determines which candidate solutions are carried over to the next generation. This is usually based on how well they solve the optimization problem, with better-performing solutions being more likely to be selected.\n",
    "\n",
    "A key aspect of DE is its flexibility and adaptability, allowing it to be applied to a wide range of optimization problems. As a metaheuristic algorithm, it makes few assumptions about the problem being optimized and is capable of exploring vast design spaces efficiently. This characteristic makes DE suitable for problems where the solution space is large or poorly understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c7314-7ccd-46de-95a4-0a22010513ae",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "1. **Parallel Computing**: DE has been utilized effectively in parallel computing environments. It's particularly useful for optimizing problems that are computationally intensive and can benefit from parallel execution.\n",
    "\n",
    "2. **Multiobjective Optimization**: DE is applied in multiobjective optimization scenarios, where it helps in finding solutions that balance trade-offs between two or more conflicting objectives.\n",
    "\n",
    "3. **Constrained Optimization**: In constrained optimization, DE helps in finding the best solution within a given set of constraints, making it suitable for real-world problems where certain limits or requirements must be met.\n",
    "\n",
    "4. **Quantitative Interpretation of Self-Potential Data in Geophysics**: DE has been successfully used for the quantitative interpretation of self-potential data in geophysics. This involves estimating parameters such as electrical dipole moment, depth of the source, and polarization angle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7767bb7",
   "metadata": {},
   "source": [
    "## Strengths\n",
    "\n",
    "1. **Handling Non-Differentiable, Nonlinear, and Multimodal Functions**: DE excels in managing non-differentiable, nonlinear, and multimodal cost functions. This capability is crucial when dealing with real-world optimization problems that are complex and don't conform to simpler, linear models.\n",
    "\n",
    "2. **Parallelizability**: The algorithm is well-suited for parallel computation, making it effective for computationally intensive tasks. This aspect allows for efficient processing of large-scale problems by distributing the workload across multiple processors or machines.\n",
    "\n",
    "3. **Ease of Use with Few Control Variables**: DE is user-friendly, requiring only a few control variables to guide the optimization process. These variables are robust and straightforward to select, reducing the complexity often associated with tuning optimization algorithms.\n",
    "\n",
    "4. **Good Convergence Properties**: It consistently converges to the global minimum in independent trials, indicating its reliability in finding optimal solutions across different problem instances.\n",
    "\n",
    "5. **Capability with Multidimensional Real-Valued Functions**: DE can optimize multidimensional real-valued functions without the need for gradient information. This means it can address optimization problems that are non-continuous, noisy, or subject to change over time, broadening its applicability.\n",
    "\n",
    "6. **Incorporates Directional Information**: Unlike conventional genetic algorithms, DE employs a target and unit vector, which allows for quicker convergence on solutions. However, this may come at the expense of exploration.\n",
    "\n",
    "7. **Simplicity and Speed**: DE is valued for its straightforwardness and rapid execution. It employs real coding, which is easy to understand and implement, and also features a local search mechanism for enhanced efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb1301",
   "metadata": {},
   "source": [
    "## Weaknesses\n",
    "\n",
    "1. **Parameter Sensitivity and Selection**: The performance of DE is highly dependent on the trial vector generation scheme and the adjustment of its control parameters. Finding the optimal values for these parameters can be time-consuming and challenging, especially for complex problems. This sensitivity necessitates a problem-specific approach to parameter selection, which can be a significant drawback in applications where quick and easy configuration is needed.\n",
    "\n",
    "2. **Effort in Fine-Tuning Parameters**: The mutation factor (F) and crossover probability (CR) are critical to DE's performance. The trial-and-error method used to fine-tune these parameters can be successful, but it demands considerable time and effort. Moreover, the optimal settings for these parameters tend to be problem-specific, adding to the complexity of using DE in diverse scenarios.\n",
    "\n",
    "3. **Selection of Penalty Coefficient**: In DE, the selection of the penalty coefficient is a significant challenge. If the penalty coefficient is set too low, it may not effectively enforce constraints. Conversely, if it's set too high, it can greatly slow down or even halt the convergence process. This aspect is crucial because it impacts the effectiveness of the algorithm in constrained optimization problems.\n",
    "\n",
    "4. **Premature Convergence and Evolutionary Stagnation**: As the DE algorithm evolves, with an increase in generations, the population diversity can worsen. This leads to premature convergence or evolutionary stagnation, which is detrimental for an algorithm that relies on population differences. This weakness is particularly problematic as it impacts the algorithm's ability to find optimal solutions in diverse scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede478d",
   "metadata": {},
   "source": [
    "## Python Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19580a",
   "metadata": {},
   "source": [
    "\n",
    "### DE on multiple complex functions\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Bellow process is intense. <br> It creates the GIF animations displayed bellow. <br> Refresh the current page to update displayed animations after a new generation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6142a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a random number generator for reproducibility (Edit seed)\n",
    "rng_engine = np.random.default_rng(seed=None)\n",
    "\n",
    "class DifferentialEvolution:\n",
    "    def __init__(self, objective_function, bounds, population_size=100, crossover_probability=0.7, differential_weight=0.8, max_generations=100):\n",
    "        \"\"\"\n",
    "        Initialize the Differential Evolution optimizer.\n",
    "\n",
    "        Args:\n",
    "        - objective_function (callable): The objective function to minimize.\n",
    "        - bounds (numpy.ndarray): An array of shape (2,) representing the lower and upper bounds of the search space.\n",
    "        - population_size (int, optional): The number of individuals in the population.\n",
    "        - crossover_probability (float, optional): The probability of crossover.\n",
    "        - differential_weight (float, optional): The differential weight used in mutation.\n",
    "        - max_generations (int, optional): The maximum number of generations for the optimization process.\n",
    "\n",
    "        Attributes:\n",
    "        - best_solution (numpy.ndarray): The best solution found during optimization.\n",
    "        - population_history (list): A history of the population for each generation.\n",
    "        - fitness_history (list): The fitness history for the best solution at each generation.\n",
    "        \"\"\"\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = bounds\n",
    "        self.population_size = population_size\n",
    "        self.crossover_probability = crossover_probability\n",
    "        self.differential_weight = differential_weight\n",
    "        self.max_generations = max_generations\n",
    "        self.dimensions = len(bounds)\n",
    "        self.population = np.random.rand(population_size, self.dimensions) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        self.best_solution = None\n",
    "        self.population_history = []\n",
    "        self.fitness_history = []\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Perform the optimization process using the Differential Evolution algorithm.\n",
    "\n",
    "        Iteratively applies mutation, crossover, and selection to evolve the population\n",
    "        towards an optimal solution.\n",
    "\n",
    "        Returns:\n",
    "        - numpy.ndarray: The best solution found during the optimization.\n",
    "        \"\"\"\n",
    "        self.fitness_history = []\n",
    "        best_fitness = float('inf')\n",
    "\n",
    "        for _ in range(self.max_generations):\n",
    "            for i in range(self.population_size):\n",
    "                # Mutation\n",
    "                idxs = [idx for idx in range(self.population_size) if idx != i]\n",
    "                a, b, c = self.population[rng_engine.choice(idxs, 3, replace=False)]\n",
    "                mutant_vector = np.clip(a + self.differential_weight * (b - c), self.bounds[0], self.bounds[1])\n",
    "\n",
    "                # Crossover\n",
    "                trial_vector = np.where(np.random.rand(self.dimensions) < self.crossover_probability, mutant_vector, self.population[i])\n",
    "\n",
    "                # Selection\n",
    "                if self.objective_function(*trial_vector) < self.objective_function(*self.population[i]):\n",
    "                    self.population[i] = trial_vector\n",
    "\n",
    "            # Find the best individual\n",
    "            fitness = np.array([self.objective_function(*ind) for ind in self.population])\n",
    "            min_fitness_idx = np.argmin(fitness)\n",
    "            min_fitness = fitness[min_fitness_idx]\n",
    "\n",
    "            if min_fitness < best_fitness:\n",
    "                best_fitness = min_fitness\n",
    "                self.best_solution = self.population[min_fitness_idx]\n",
    "            \n",
    "            self.fitness_history.append(best_fitness)\n",
    "            self.population_history.append(self.population.copy())\n",
    "\n",
    "        return self.best_solution\n",
    "    \n",
    "    def plot_fitness(self):\n",
    "        \"\"\"\n",
    "        Plot the fitness history of the optimization process.\n",
    "\n",
    "        Generates a plot showing how the fitness of the best solution\n",
    "        evolves over generations.\n",
    "        \"\"\"\n",
    "        plt.plot(self.fitness_history)\n",
    "        plt.title(\"Differential Evolution Optimization\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Best Fitness (Objective Function Value)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "178d5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastrigin_function(x, y):\n",
    "    \"\"\"\n",
    "    Calculate the Rastrigin function.\n",
    "\n",
    "    The Rastrigin function is a non-convex function used as a performance test\n",
    "    problem for optimization algorithms. It is known for its large number of\n",
    "    local minima.\n",
    "\n",
    "    Args:\n",
    "    - x (float): The x-coordinate.\n",
    "    - y (float): The y-coordinate.\n",
    "\n",
    "    Returns:\n",
    "    - float: The value of the Rastrigin function at (x, y).\n",
    "    \"\"\"\n",
    "    A = 10\n",
    "    n = 2\n",
    "    return A * n + (x**2 - A * np.cos(2 * np.pi * x)) + (y**2 - A * np.cos(2 * np.pi * y))\n",
    "\n",
    "def ackley_function(x, y):\n",
    "    \"\"\"\n",
    "    Calculate the Ackley function.\n",
    "\n",
    "    The Ackley function is widely used for testing optimization algorithms.\n",
    "    It is characterized by a nearly flat outer region and a large hole at the center.\n",
    "\n",
    "    Args:\n",
    "    - x (float): The x-coordinate.\n",
    "    - y (float): The y-coordinate.\n",
    "\n",
    "    Returns:\n",
    "    - float: The value of the Ackley function at (x, y).\n",
    "    \"\"\"\n",
    "    a = 20\n",
    "    b = 0.2\n",
    "    c = 2 * np.pi\n",
    "    sum_sq_term = -0.5 * (x**2 + y**2)\n",
    "    cos_term = np.cos(c * x) + np.cos(c * y)\n",
    "    return -a * np.exp(b * sum_sq_term) - np.exp(0.5 * cos_term) + a + np.exp(1)\n",
    "\n",
    "def rosenbrock_function(x, y, a=1, b=100):\n",
    "    \"\"\"\n",
    "    Calculate the Rosenbrock function.\n",
    "\n",
    "    The Rosenbrock function, also known as the Valley or Banana function,\n",
    "    is a popular test problem for gradient-based optimization algorithms.\n",
    "\n",
    "    Args:\n",
    "    - x (float): The x-coordinate.\n",
    "    - y (float): The y-coordinate.\n",
    "    - a (float, optional): The parameter a. Default is 1.\n",
    "    - b (float, optional): The parameter b. Default is 100.\n",
    "\n",
    "    Returns:\n",
    "    - float: The value of the Rosenbrock function at (x, y).\n",
    "    \"\"\"\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "def goldstein_price_function(x, y):\n",
    "    \"\"\"\n",
    "    Calculate the Goldstein-Price function.\n",
    "\n",
    "    The Goldstein-Price function is a complex, multimodal function used\n",
    "    as a benchmark in optimization. It has several local minima.\n",
    "\n",
    "    Args:\n",
    "    - x (float): The x-coordinate.\n",
    "    - y (float): The y-coordinate.\n",
    "\n",
    "    Returns:\n",
    "    - float: The value of the Goldstein-Price function at (x, y).\n",
    "    \"\"\"\n",
    "    part1 = (1 + (x + y + 1)**2 * (19 - 14*x + 3*x**2 - 14*y + 6*x*y + 3*y**2))\n",
    "    part2 = (30 + (2*x - 3*y)**2 * (18 - 32*x + 12*x**2 + 48*y - 36*x*y + 27*y**2))\n",
    "    return part1 * part2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea1f580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution for Rosenbrock_DE (x, y) = (0.9690064190877372, 0.9355586337894115) with value z = 0.002126692362645805 \n",
      " Saved at ./assets/images/Rosenbrock_DE/Rosenbrock_DE.gif \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_frame(frame, trails, fitness_history, function, function_name, X, Y, Z, known_optima, save_path):\n",
    "    \"\"\"\n",
    "    Generate and save plots for a specific frame in the optimization process.\n",
    "\n",
    "    Args:\n",
    "    - frame (int): The current iteration/frame number.\n",
    "    - trails (list): A list of trails for each particle or agent.\n",
    "    - fitness_history (list): The history of fitness values across generations.\n",
    "    - function (callable): The objective function being optimized.\n",
    "    - function_name (str): The name of the objective function.\n",
    "    - X, Y, Z (numpy.ndarray): Meshgrid arrays for plotting the function surface.\n",
    "    - known_optima (list): Coordinates of the known optimal points.\n",
    "    - save_path (str): The file path to save the plot image.\n",
    "\n",
    "    This function creates a figure with a 2x2 grid of subplots:\n",
    "    - The first subplot (top left) is a 2D contour plot of the function surface.\n",
    "    - The second subplot (top right) is a 3D surface plot of the function.\n",
    "    - The third subplot (bottom row) is a line plot showing the fitness history.\n",
    "    The function also plots the current position of agents and known optima.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Set the title for the entire figure\n",
    "    fig.suptitle(f\"{function_name} function - Iteration {frame}\", fontsize=16)\n",
    "\n",
    "    # 2D plot\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.contourf(X, Y, Z, levels=200, cmap='viridis')\n",
    "    for trail in trails:\n",
    "        if len(trail) > frame:\n",
    "            ax1.plot(*trail[frame], 'ro')\n",
    "    ax1.set_title(\"2D View\")\n",
    "\n",
    "    # 3D plot\n",
    "    ax2 = fig.add_subplot(222, projection='3d')\n",
    "    ax2.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.7)\n",
    "    for trail in trails:\n",
    "        if len(trail) > frame:\n",
    "            ax2.scatter(*trail[frame], function(*trail[frame]), color='r', s=50)\n",
    "\n",
    "    # Plotting known optima\n",
    "    for opt in known_optima:\n",
    "        ax1.scatter(opt[0], opt[1], color='green', s=300, marker='x', label='Known Optima')\n",
    "        ax2.scatter(opt[0], opt[1], opt[2], color='green', s=500, marker='x', label='Known Optima')\n",
    "\n",
    "    ax2.set_title(\"3D View\")\n",
    "    ax2.set_xlabel('X axis')\n",
    "    ax2.set_ylabel('Y axis')\n",
    "    ax2.set_zlabel('Z axis')\n",
    "    ax2.legend()\n",
    "\n",
    "    # Fitness History Plot\n",
    "    ax3 = fig.add_subplot(212)\n",
    "    ax3.plot(fitness_history[:frame+1])\n",
    "    ax3.set_title(\"Fitness History\")\n",
    "    ax3.set_xlabel(\"Generation\")\n",
    "    ax3.set_ylabel(\"Best Fitness (Objective Function Value)\")\n",
    "\n",
    "    plt.close(fig)\n",
    "    fig.savefig(save_path)\n",
    "\n",
    "\n",
    "def create_gif(function, function_name, num_iterations, bounds, population_size, crossover_probability, differential_weight, known_optima):\n",
    "    \"\"\"\n",
    "    Create a GIF animation visualizing the optimization process of the Differential Evolution algorithm.\n",
    "\n",
    "    Args:\n",
    "    - function (callable): The objective function to be optimized.\n",
    "    - function_name (str): The name of the function, used for saving files.\n",
    "    - num_iterations (int): The number of iterations to perform optimization and create frames for the GIF.\n",
    "    - bounds (list): The lower and upper bounds of the search space.\n",
    "    - population_size (int): The size of the population in the DE algorithm.\n",
    "    - crossover_probability (float): The crossover probability in the DE algorithm.\n",
    "    - differential_weight (float): The differential weight in the DE algorithm.\n",
    "    - known_optima (list): Known optimal points of the function, for reference in the visualization.\n",
    "\n",
    "    This function performs the optimization using DE, then creates and saves a GIF visualizing the process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize DE with the provided parameters\n",
    "    de = DifferentialEvolution(function, bounds, population_size, crossover_probability, differential_weight, num_iterations)\n",
    "    de.optimize()\n",
    "\n",
    "    # Set up the grid for visualizing the function's landscape\n",
    "    x = np.linspace(bounds[0], bounds[1], 200)\n",
    "    y = np.linspace(bounds[0], bounds[1], 200)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = function(X, Y)\n",
    "\n",
    "    # Initialize directory for saving frames\n",
    "    gif_dir = f\"./assets/images/{function_name}\"\n",
    "    os.makedirs(gif_dir, exist_ok=True)\n",
    "    filenames = []\n",
    "\n",
    "    # Generate frames for each iteration\n",
    "    for frame in range(num_iterations):\n",
    "        frame_path = f\"{gif_dir}/frame_{frame:04d}.png\"\n",
    "        plot_frame(frame, de.population_history, de.fitness_history, function, function_name, X, Y, Z, known_optima, frame_path)\n",
    "        filenames.append(frame_path)\n",
    "    \n",
    "    # Create and save the GIF\n",
    "    gif_path = f\"{gif_dir}/{function_name}.gif\"\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=0.2, loop=0) as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # Remove the individual frame files\n",
    "    for filename in filenames:\n",
    "        os.remove(filename)\n",
    "\n",
    "    # Output information about the best solution found\n",
    "    best_position = de.best_solution\n",
    "    best_value = de.objective_function(*best_position)\n",
    "    print(f\"Best solution for {function_name} (x, y) = ({best_position[0]}, {best_position[1]}) with value z = {best_value} \\n Saved at {gif_path} \\n\")\n",
    "\n",
    "known_optima_rastrigin = [(0, 0, 0)] # x, y, z\n",
    "known_optima_ackley = [(0, 0, 0)] # x, y, z\n",
    "known_optima_rosenbrock = [(1, 1, 0)] # x, y, z\n",
    "known_optima_goldstein_price = [(0, -1, 3)] # x, y, z\n",
    "\n",
    "bounds = [-6, 6]\n",
    "# bounds:\n",
    "# Defines the range of the search space for each dimension of the problem. In this case, the bounds are set to [-10, 10],\n",
    "# meaning that the algorithm will search for solutions within this interval for each variable. Appropriate bounds are\n",
    "# crucial as they can affect the efficiency of the search process and the quality of the final solution.\n",
    "\n",
    "population_size = 100\n",
    "# population_size:\n",
    "# Specifies the number of candidate solutions (individuals) in the population. A larger population size allows for a\n",
    "# wider exploration of the search space, potentially leading to better solutions but at the cost of increased computational\n",
    "# effort. Conversely, a smaller population size might reduce the computational load but can risk missing out on\n",
    "# potentially better solutions.\n",
    "\n",
    "max_generations = 100\n",
    "# max_generations:\n",
    "# Determines the number of iterations (generations) the algorithm will run. This is a stopping criterion for the algorithm.\n",
    "# A larger number of generations allows for more thorough exploration of the search space, increasing the chances of\n",
    "# finding an optimal or near-optimal solution. However, it also means more computational time.\n",
    "\n",
    "crossover_probability = 0.5\n",
    "# crossover_probability:\n",
    "# Indicates the probability of crossover (genetic recombination) occurring during the generation of trial vectors. A value\n",
    "# of 0.5 means there is a 50% chance that each component of the trial vector is taken from the mutant vector. This\n",
    "# parameter balances between exploration (high values) and exploitation (low values) of the search space.\n",
    "\n",
    "differential_weight = 1\n",
    "# differential_weight:\n",
    "# This parameter, often denoted as F, controls the amplification of the differential variation between two population\n",
    "# members. It influences the step sizes in the mutation process. A value of 0.6 suggests moderate perturbations in the\n",
    "# generation of mutant vectors. Higher values can lead to more aggressive exploration but may also increase the risk of\n",
    "# overshooting optimal solutions, while lower values tend to encourage more localized search.\n",
    "\n",
    "\n",
    "# create_gif(rastrigin_function, 'Rastrigin_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_rastrigin)\n",
    "# create_gif(ackley_function, 'Ackley_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_ackley)\n",
    "create_gif(rosenbrock_function, 'Rosenbrock_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_rosenbrock)\n",
    "# create_gif(goldstein_price_function, 'Goldstein_Price_DE', max_generations, bounds, population_size, crossover_probability, differential_weight, known_optima_goldstein_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ba8ce",
   "metadata": {},
   "source": [
    "![](../../assets/images/Ackley_DE/Ackley_DE.gif)\n",
    "<br>\n",
    "\n",
    "![](../../assets/images/Goldstein_Price_DE/Goldstein_Price_DE.gif)\n",
    "<br>\n",
    "\n",
    "![](../../assets/images/Rastrigin_DE/rastrigin_DE.gif)\n",
    "<br>\n",
    "\n",
    "![](../../assets/images/Rosenbrock_DE/rosenbrock_DE.gif)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of demonstration\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Optimization Tools\n",
    "\n",
    "2. [**DEAP (Python):**](https://github.com/DEAP/deap) DEAP (Distributed Evolutionary Algorithms in Python) is an open-source framework for evolutionary computation. It provides a versatile collection of evolutionary algorithms, including differential evolution. DEAP stands out for its ease of use and flexibility, allowing users to easily customize genetic algorithms and other evolutionary strategies for their specific problems.\n",
    "\n",
    "3. [**Julia (Julia Language):**](https://julialang.org/) Julia, a high-performance programming language for technical computing, includes various packages for optimization and evolutionary algorithms. One such package is `BlackBoxOptim`, which supports differential evolution. Julia is renowned for its speed and efficiency, particularly in mathematical computing, making it a popular choice for implementing complex algorithms like differential evolution.\n",
    "\n",
    "4. [**Nevergrad (Python):**](https://github.com/facebookresearch/nevergrad) Nevergrad is an open-source Python library designed for derivative-free and blackbox optimization. It includes a wide range of optimization algorithms, including differential evolution. Known for its ability to handle noisy, real-world problems, Nevergrad is widely used in both academia and industry for optimization tasks that are difficult to model explicitly.\n",
    "\n",
    "5. [**Jenetics (Java):**](https://jenetics.io/) Jenetics is an advanced Genetic Algorithm, respectively an Evolutionary Algorithm, library written in modern-day Java. It includes support for differential evolution as part of its suite of evolutionary algorithms. Jenetics is appreciated for its robustness and performance, making it a strong choice for Java developers needing evolutionary computation capabilities.\n",
    "\n",
    "5. [**Pagmo/Pygmo (C++/Python):**](https://www.esa.int/gsp/ACT/open_source/pagmo/) Pagmo is a C++ library for scientific computing and optimization, particularly focused on global and multi-objective optimization problems. It includes the differential evolution algorithm among many other optimization algorithms. Pygmo is the Python version of this library. Pagmo is distinguished by its architecture that facilitates solving complex optimization problems and its integration with other scientific tools in C++ and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "| Sources |\n",
    "|---------|\n",
    "| [Differential evolution - Wikipedia](https://en.wikipedia.org/wiki/Differential_evolution) |\n",
    "| [Differential Evolution from Scratch in Python - Machinelearningmastery](https://machinelearningmastery.com/differential-evolution-from-scratch-in-python/) |\n",
    "| [Exploring differential evolution in AI - indiaai](https://indiaai.gov.in/article/exploring-differential-evolution-in-ai) |\n",
    "| [A Comparative Study of Differential Evolution Variants in Constrained Structural Optimization - Frontiers](https://www.frontiersin.org/articles/10.3389/fbuil.2020.00102/full) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
