{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d5ef08",
   "metadata": {},
   "source": [
    "# Newton-Raphson method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfa78c",
   "metadata": {},
   "source": [
    "## Understanding the algorithm\n",
    "\n",
    "L'algorithme de Newton, également connu sous le nom de méthode de Newton-Raphson, est une technique basique pour trouver rapidement et de manière itérative les racines réelles d'une fonction réelle. L'idée de base est d'utiliser la tangente à la courbe de la fonction pour estimer où la fonction elle-même coupe l'axe des x, c'est-à-dire là où la fonction s'annule.\n",
    "Méthode utilisée pour des problèmes d'optimisation continue, en particulier pour des fonctions lisses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c7314-7ccd-46de-95a4-0a22010513ae",
   "metadata": {},
   "source": [
    "## Usage examples\n",
    "\n",
    "La méthode de Newton est utilisée dans de nombreux domaines, y compris:\n",
    "\n",
    "- En sciences et en ingénierie pour résoudre des équations non linéaires.\n",
    "- En optimisation pour trouver les points où la dérivée première d'une fonction est nulle, c'est-à-dire les minima, les maxima et les points d'inflexion.\n",
    "- En finance pour évaluer des instruments financiers, comme les options, où l'équation de Black-Scholes peut être résolue pour la volatilité implicite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7767bb7",
   "metadata": {},
   "source": [
    "## Strengths\n",
    "\n",
    "1. Convergence rapide: L'algorithme de Newton est très rapide quand il converge, surtout si la solution initiale est proche de la racine vraie.\n",
    "2. Efficacité: Il nécessite moins d'itérations par rapport à d'autres méthodes telles que la méthode de la bissection ou la méthode du point fixe.\n",
    "3. Précision: La méthode peut être très précise avec suffisamment d'itérations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb1301",
   "metadata": {},
   "source": [
    "## Weaknesses\n",
    "\n",
    "- Choix de l'initialisation: Le succès de la méthode dépend fortement de la valeur initiale. Un mauvais choix peut conduire à une convergence vers la mauvaise - racine ou à une divergence.\n",
    "- Nécessité de la dérivée: Il faut pouvoir calculer la dérivée première de la fonction, ce qui peut être complexe pour certaines fonctions.\n",
    "- Échec sur les points singuliers: Si la dérivée première est nulle au point de racine ou près de celle-ci, la méthode peut échouer ou avoir une convergence très lente.\n",
    "- Pas de garantie de convergence: Pour certaines fonctions, la méthode peut ne pas converger du tout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede478d",
   "metadata": {},
   "source": [
    "## Python demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c418c639-2bfa-462a-ad4c-f3c426a8ac0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trouvé la solution après 5 itérations.\n",
      "La racine est: 3.0000000149658455\n"
     ]
    }
   ],
   "source": [
    "def newton_method(f, df, x0, tol, max_iter):\n",
    "    \"\"\"\n",
    "    f : La fonction dont on cherche la racine.\n",
    "    df: La dérivée de la fonction f.\n",
    "    x0: Valeur initiale.\n",
    "    tol: La tolérance, qui détermine la précision de la solution.\n",
    "    max_iter: Le nombre maximal d'itérations.\n",
    "    \"\"\"\n",
    "    xn = x0\n",
    "    for n in range(0, max_iter):\n",
    "        fxn = f(xn)\n",
    "        if abs(fxn) < tol:\n",
    "            print('Trouvé la solution après', n, 'itérations.')\n",
    "            return xn\n",
    "        dfxn = df(xn)\n",
    "        if dfxn == 0:\n",
    "            print('La dérivée est nulle. Pas de solution trouvée.')\n",
    "            return None\n",
    "        xn = xn - fxn/dfxn\n",
    "    print('Exceedé le nombre maximal d\\'itérations. Pas de solution.')\n",
    "    return None\n",
    "\n",
    "# Exemple d'utilisation de la méthode de Newton:\n",
    "# On cherche la racine de f(x) = x^2 - 9\n",
    "\n",
    "f = lambda x: x**2 - 9\n",
    "df = lambda x: 2*x\n",
    "x0 = 10\n",
    "tol = 0.000001\n",
    "max_iter = 10\n",
    "\n",
    "root = newton_method(f, df, x0, tol, max_iter)\n",
    "print(\"La racine est:\", root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b216c08",
   "metadata": {},
   "source": [
    "Dans cet exemple, la fonction f est \n",
    "x^2 − 9, dont on sait que la racine est ±3. La dérivée df est 2x. \n",
    "On commence avec une estimation initiale x0 de 10. La tolérance tol est fixée à une petite valeur pour une grande précision, et max_iter limite le nombre d'itérations pour éviter une boucle infinie dans le cas où la méthode ne converge pas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c85b7d",
   "metadata": {},
   "source": [
    "End of demonstration\n",
    "\n",
    "---\n",
    "\n",
    "## Practical optimization tools\n",
    "\n",
    "1. [**NumPy (Python):**](https://numpy.org/) NumPy, a fundamental package for scientific computing in Python, is extensively used for numerical operations. While it doesn't provide direct implementations of Newton or quasi-Newton methods, its powerful array and matrix processing capabilities enable users to implement these methods efficiently. NumPy is integral to the Python data science stack and is often used in conjunction with SciPy and other libraries to solve optimization problems.\n",
    "\n",
    "2. [**Julia (Julia Language):**](https://julialang.org) Julia, a high-performance programming language for technical computing, features robust optimization packages. One such package is `Optim.jl`, which offers a variety of optimization algorithms, including Newton and quasi-Newton methods. Its strength lies in the language's speed and ease of use, making it a popular choice for tasks requiring high computational efficiency.\n",
    "\n",
    "3. [**GNU Octave:**](https://octave.org) GNU Octave, primarily intended for numerical computations, provides a convenient interface for solving optimization problems. It includes functions for applying Newton and quasi-Newton methods in its optimization toolbox. Octave is widely recognized for its MATLAB-like syntax, making it a go-to option for users familiar with MATLAB seeking an open-source alternative.\n",
    "\n",
    "4. [**R (stats and optimx packages):**](https://www.r-project.org) R, a language and environment for statistical computing and graphics, offers several packages for optimization. The `stats` package includes functions for optimization, and `optimx` enhances these capabilities, providing an array of optimization methods, including Newton and quasi-Newton algorithms. R's popularity in the statistical and data analysis community makes these packages widely used for optimization problems in these domains.\n",
    "\n",
    "5. [**Eigen (C++):**](https://eigen.tuxfamily.org/index.php?title=Main_Page) Eigen, a C++ template library for linear algebra, includes capabilities for solving optimization problems. While primarily focused on matrix operations, its versatility allows for the implementation of Newton and quasi-Newton methods within a high-performance, low-level computing environment. Eigen is well-regarded for its efficiency and is widely used in applications that require heavy linear algebra computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457aaf3-dad6-4935-8c0a-e0e59091d3cc",
   "metadata": {},
   "source": [
    "## Sources\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
